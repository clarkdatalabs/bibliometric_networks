{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bibliographic Networks: A Python Tutorial\n",
    "\n",
    "Networks can provide significant measures to identify data driven patterns and dependencies. Though, given a data file it can be difficult to discern how one may approach creating such a network. In this tutorial, we will use a bibliographic data file downloaded from a query search in [Scopus](https://https://www.scopus.com/search/form.uri) to walk through the process of cleaning the data file, writing a python script to parse the data into nodes and edges, computing graphical measures using [NetworkX](https://https://networkx.github.io/documentation/stable/index.html), and creating an interactive network display using [HoloViews](https://http://holoviews.org). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Data Manipulation in Excel\n",
    "\n",
    "As you are editing and cleaning your data set, be sure to always save in Excel as <i>CSV UTF-8 (Comma delimited) (.csv)</i>. This will ensure that the data file is readable by the Python reader used in this tutorial, and will keep any special characters. \n",
    "\n",
    "#### Scopus Specific Data Manipulation \n",
    "Few Scopus downloadable queries are perfect. This tutorial uses the Scopus file containing results for the query <i>economics AND \"complex systems.\"</i> Upon downloading this data file, some rows are skewed from inaccurate reading and parsing. If you are costumizing this tutorial, simply scroll through the file and delete any rows where the data is clearly mismatched (i.e. an author name in the 'Title' column, a numerical value in a non-numerical column, etc.). \n",
    "\n",
    "Additionally, across several different queries, we discovered duplicates in entry 'Title,' with other columns containing conflicting data. To fix this issue for the purposes of producing a network, duplicates should be removed. With your .csv file open in Excel, select <i>Data -> Table Tools -> Remove Duplicates</i>. Indicate that the .csv file has headers, as all Scopus files will, and only select the 'Title' column by which duplicates will be identified. After executing this command, it is important to again save the file as a .csv. Otherwise, Excel may default to saving the file as a .txt, or another format, and data features may be lost. By continuously saving the file as a .csv, we ensure that it will continue to be compatible with the Python code for this tutorial.\n",
    "\n",
    "Generally, for the case of creating a connected network, we want the rows in our bibliographic data file to have a unique title and a list of references. Other customizations can be made as long as this feature is preserved. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Import Necessary Libraries and Packages \n",
    "The following code will download the necessary libraries and packages for this tutorial. To customize this tutorial, decalare your own .csv file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "!pip install networkx -q\n",
    "!pip install numpy -q\n",
    "!pip install pandas -q\n",
    "!pip install holoviews -q\n",
    "!pip install bokeh -q\n",
    "!pip install scikit-image -q\n",
    "!pip install xarray -q\n",
    "!pip install datashader -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named networkx",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-44ddab2a1301>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcsv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mnetworkx\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mholoviews\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mhv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named networkx"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import holoviews as hv\n",
    "from holoviews.operation.datashader import datashade, bundle_graph\n",
    "from networkx.algorithms import community\n",
    "\n",
    "file_name = 'scopus.csv' # TODO: insert filename if customizing this tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Partitioning the Data into Nodes and Edges\n",
    "\n",
    "This Python script is specific to SCOPUS and bibliometric data, though could be easily customized to match the parameters of any data file. \n",
    "\n",
    "To make a network, we must identify objects and relationships between objects. With bibliometric data, we can identify titles and designate a connection between titles if one is referenceing the other. The downloaded Scopus file identifies a title for a source in each row. The column 'References' indicates a semicolon delimited list of references in MLA or APA format. To make this information useful, we must parse an identifying title from each reference in the list. Because the Scopus file does not maintain consistent formatting accross references, we simply keep the entire reference and search for strings inside strings, though this could be customized depending on data file formatting. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_list = [] # a list of titles and references\n",
    "edge_list = [] # includes rows of format [a, b] where 'a' references 'b'\n",
    "type_dict = {} # key: node, value: type ('title' or 'reference'), holds all possible node values\n",
    "\n",
    "''' \n",
    "Requires: 'n_type' is either 'title' or 'reference' \n",
    "Modifies: If 'node' occurs in the list, preserves type 'title,' changing either \n",
    "          the 'node_list' value and the 'type_dict' type, or just the 'node' value.\n",
    "          Else, adds 'node' to 'node_list.'\n",
    "Effects:  Compares 'node' to the current 'note_list.' \n",
    "'''\n",
    "def comp_add(node_list, node, n_type):\n",
    "    for i in range(len(node_list)): \n",
    "        # check to see if 'node' compares to any current nodes\n",
    "        if node in node_list[i] or node_list[i] in node: \n",
    "            # if a node exists as a row 'title' and a row 'reference', \n",
    "            # we want to favor the type 'title' in our data structures \n",
    "            if n_type == 'title': \n",
    "                # switch the representation in 'node_list' to 'title'\n",
    "                node_list[i] = node\n",
    "                type_dict[node] = n_type \n",
    "            else:\n",
    "                # switch the representation of 'node' to 'title' \n",
    "                node = node_list[i]\n",
    "            return node \n",
    "        \n",
    "    # the rest of this function executes if 'node' is not already in 'node_list'\n",
    "    if n_type == 'title':\n",
    "        node_list.append(node)\n",
    "        type_dict[node] = n_type\n",
    "    else: \n",
    "        node_list.append(node)\n",
    "        type_dict[node] = n_type\n",
    "\n",
    "    return node\n",
    "\n",
    "''' \n",
    "Main loop to parse data into nodes and edges. \n",
    "'''\n",
    "with open(file_name) as csv_file:\n",
    "    reader = csv.DictReader(csv_file)\n",
    "    for row in reader:\n",
    "        # add node with unique identifier\n",
    "        source_node = row['Title']\n",
    "        source_node = comp_add(node_list, source_node, 'title')\n",
    "        # add an edge for each source and its references\n",
    "        refs = row['References'].split(';')\n",
    "        for ref in refs:\n",
    "            # disregard web references, and clean data for any formatting inconsistencies\n",
    "            if 'https://' not in ref and 'http://' not in ref and ref != \" \" and ref != \"\":  \n",
    "                ref = comp_add(node_list, ref, 'reference')\n",
    "                edge = [source_node, ref] # 'source_node' references 'ref'\n",
    "                edge_list.append(edge) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Graph Manipulation \n",
    "Once you have created an <i>edge_list</i> variable, edges can be added to a NetworkX graph. Using NetworkX for this graph manipulation is intuitive and clean, requiring minimal lines of code. We use a directed graph so that we can determine the frequency by which a node is being referenced, as opposed to the frequency by which a node is referencing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "G = nx.DiGraph()\n",
    "for n in node_list: \n",
    "    G.add_node(n)\n",
    "G.add_edges_from(edge_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a large graph, depending on the information being represented, one may want to prune the graph to only contain nodes with a degree (the number of connections to a single node) greater than 1. For this bibliometric data, we are primarily interested in the connections between nodes, therefore a node with only one connection is of much less importance. Furthermore, by removing less significant nodes, we can decrease the graph size significantly, creating a more easily understood graphical layout. Be careful to run this code only as many times as you wish to reduce the graph, or else significant information may be lost as the graph is pruned, depending on the degree of interest in the information.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# by running this code once, all isolated subgraphs will be removed \n",
    "\n",
    "# first remove nodes of degree 1\n",
    "nodes_to_remove = []\n",
    "for n in G.nodes(): \n",
    "    if G.degree(n) == 1: \n",
    "        nodes_to_remove.append(n)\n",
    "G.remove_nodes_from(nodes_to_remove)\n",
    "\n",
    "# then remove nodes that are isolated \n",
    "nodes_to_remove = []\n",
    "for n in G.nodes(): \n",
    "    if G.degree(n) == 0: \n",
    "        nodes_to_remove.append(n)\n",
    "G.remove_nodes_from(nodes_to_remove)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have pruned our graph, to give the nodes a distinguishable measure, we indicate a label for each node corresponding to its type, and a measure of degree. This part could be customized to distinguish a node by any measure. By adding attributes in this way, they will carry over to HoloViews.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for n in G.nodes:\n",
    "    G.node[n]['label'] = type_dict[n]\n",
    "    G.node[n]['in-degree'] = G.in_degree(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we will run the [NetworkX Girvan Newman] (https://networkx.github.io/documentation/latest/reference/algorithms/generated/networkx.algorithms.community.centrality.girvan_newman.html) algorithm on the graph to identify community structure. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "communities_generator = community.girvan_newman(G)\n",
    "communities = next(communities_generator)\n",
    "\n",
    "# sort the communities based on size \n",
    "groups = []\n",
    "for c in communities: \n",
    "    size = len(c)\n",
    "    groups.append([size, list(c)])\n",
    "groups.sort(reverse=True)\n",
    "\n",
    "# give each node a community id to which it belongs \n",
    "# groups with a lower 'group_id' will be a member of a larger group\n",
    "group_id = 1\n",
    "for group in groups:\n",
    "    members = group[1]\n",
    "    for n in members: \n",
    "        G.node[n]['community'] = group_id\n",
    "    group_id += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Creating a Graphical Display\n",
    "See inline comments for any places for further customization. A brief discussion of specific functions and layouts are provided in the GitHub README. \n",
    "\n",
    "##### Functionality for the Following Display \n",
    "Nodes are sized according to their in-degree, a measure of the number of sources that are referencing the node. Colors are assigned according to the NetworkX Girvan Newman community identification algorithm. Edges are bundled to create a clear flow of connection, as opposed to a cluttered, overlapping display. Hover over an edge to identify the end nodes of an edge. End nodes will be highlighted in green when hovering over an edge.       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hv.extension('bokeh')\n",
    "kwargs = dict(width=1000, height=1000, xaxis=None, yaxis=None)\n",
    "hv.opts.defaults(hv.opts.Nodes(**kwargs), hv.opts.Graph(**kwargs)) \n",
    "\n",
    "# choose a NetworkX graphical layout \n",
    "pos = nx.spring_layout(G,k=0.15, iterations=20) \n",
    "# collect graph from NetworkX \n",
    "my_graph = hv.Graph.from_networkx(G, pos)\n",
    "# bundle edges \n",
    "bundled = bundle_graph(my_graph)\n",
    "bundled.opts(padding=0.1) \n",
    "# add community and in-degree features\n",
    "bundled.opts(node_color=hv.dim('community'), node_size=((hv.dim('in-degree') + 1)*5), width=1000, \n",
    "                          cmap='Colorblind')\n",
    "bundled.opts(inspection_policy='edges')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
