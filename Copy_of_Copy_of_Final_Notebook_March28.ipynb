{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Copy of Final_Notebook_March28.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/clarkdatalabs/bibliometric_networks/blob/master/Copy_of_Copy_of_Final_Notebook_March28.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "BH7cZp0Z0WZR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Bibliographic Networks: A Python Tutorial\n",
        "\n",
        "Networks can provide significant measures to identify data driven patterns and dependencies. Though, given a data file it can be difficult to discern how one may approach creating such a network. In this tutorial, we will use a bibliographic data file downloaded from a query search in [Scopus](https://https://www.scopus.com/search/form.uri) to walk through the process of cleaning the data file, writing a python script to parse the data into nodes and edges, computing graphical measures using [NetworkX](https://https://networkx.github.io/documentation/stable/index.html), and creating an interactive network display using [HoloViews](https://http://holoviews.org). "
      ]
    },
    {
      "metadata": {
        "id": "qJ8c_hOI05bF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##1. Data Manipulation in Excel\n",
        "\n",
        "As you are editing and cleaning your data set, be sure to always save in Excel as <i>CSV UTF-8 (Comma delimited) (.csv)</i>. This will ensure that the data file is readable by the Python reader used in this tutorial, and will keep any special characters.\n",
        "\n",
        "####SCOPUS Specific Data Manipulation\n",
        "Few SCOPUS downloadable queries are perfect. This tutorial uses the SCOPUS file containing results for the query <i>economics AND \"complex systems.\"</i> Upon downloading this specific data file, some rows are skewed from inaccurate reading and parsing. If you are costumizing this tutorial, simply scroll through the file and delete any rows where the data is clearly mismatched (i.e. an author name in the 'Title' column, a numerical value in a non-numerical column, etc.).\n",
        "\n",
        "\n",
        "Additionally, across several different queries, we discovered duplicates in entry 'Title,' with other columns containing conflicting data. To fix this issue for the purposes of producing a network, duplicates should be removed. With your .csv file open on Excel, select <i>Data -> Table Tools -> Remove Duplicates</i>. Indicate that the .csv file has headers, as all SCOPUS files will, and only select the 'Title' column by which duplicates will be identified. After executing this command, it is important to save the file as a .csv as previously indicated. Otherwise, Excel may default to saving the file as a .txt, or another format, and data features may be lost. By continuously saving the file as a .csv, we ensure that it will continue to be compatible with the Python code for this tutorial.\n",
        "\n",
        "\n",
        "Generally, for the case of creating a connected network, we want the rows in our bibliographic data file to have a unique title and a list of references. Other customizations can be made as long as this feature is preserved. "
      ]
    },
    {
      "metadata": {
        "id": "VQHr-aaI0-IN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##**2. Coding Environment**\n",
        "While we originally developed this script in a local notebook, we found that running it through Google's cloud-based Jupyter notebook environment [Colaboratory](https://colab.research.google.com/) is smoother for general use. Colaboratory allows you to use and share Jupyter notebooks from your browser, without having to download, install, or run anything on your own computer. Notebooks can be saved to your Google Drive, Github or downloaded locally. Learn more about Colab [here](https://research.google.com/colaboratory/faq.html). You can run this notebook in Colaboratory by clicking this icon at the top of the notebook, downlading the notebook and importing it to Colaboratory manually, or downloading the notebook to run locally. \n"
      ]
    },
    {
      "metadata": {
        "id": "COMVogq01MXD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Import Necessary Libraries and Packages \n",
        "The following code will import and install the necessary libraries and packages for this tutorial into your Colaboratory environment or your local computing environment, if using.\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "kLjh97y500uh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install networkx -q\n",
        "!pip install numpy -q\n",
        "!pip install pandas -q\n",
        "!pip install holoviews -q\n",
        "!pip install bokeh -q\n",
        "!pip install scikit-image -q\n",
        "!pip install xarray -q\n",
        "!pip install datashader -q\n",
        "\n",
        "# To use Colaboratory w/ Google Drive\n",
        "!pip install -U -q PyDrive\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "H4AEa7LT1X96",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import csv, os\n",
        "import networkx as nx\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import holoviews as hv\n",
        "from holoviews import opts \n",
        "from holoviews.operation.datashader import datashade, bundle_graph\n",
        "from networkx.algorithms import community\n",
        "\n",
        "# To use Colaboratory w/ Google Drive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "o3Qe_gwAmcGi",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The first time you run the notebook in Colaboratory, you will have to authenticate and create the PyDrive client:"
      ]
    },
    {
      "metadata": {
        "id": "FSz6feeomaAn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# This only needs to be done once per notebook.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_zn27vi01wpB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###Insert your own file\n",
        "To customize this tutorial, decalare your own *.csv* file. If running in Colaboratory, put the *.csv* in your Google Drive and paste the File Name and File ID below. To find the File ID: upload the file to Google Drive, click \"get sharable link.\" The File ID is in the URL. \n",
        "\n",
        "> Example: https://drive.google.com/open?id=laggVyWshwcyP6kEI-y_W3P8D26sz\n",
        "\n",
        "> The File ID in this case is: *laggVyWshwcyP6kEI-y_W3P8D26sz*\n",
        "\n",
        "Alternatively, learn how to import data from GitHub [here](https://https://medium.com/@yuraist/how-to-upload-your-own-dataset-into-google-colab-e228727c87e9). \n"
      ]
    },
    {
      "metadata": {
        "id": "IzFfMfbkJCHj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "You can't permanently store a file on colab. Though you can import files from your drive and everytime when you are done with file you can save it back."
      ]
    },
    {
      "metadata": {
        "id": "JKOuAkmBq5bC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "file_name = 'scopus.csv' # TODO: insert filename\n",
        "file_id = \"1gUaltQnud-pikIQErJKFw81DsJMzcCb6\" # TODO: insert file id in quotes"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7AoAC7CZ5ESr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "downloaded = drive.CreateFile({'id': file_id})\n",
        "downloaded.GetContentFile(file_name)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9R-aaxei9S2i",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "data = pd.read_csv(file_name) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-oDWXtqc165m",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# **TO DO**\n",
        "\n",
        "\n",
        "*   mention something about saving\n",
        "* mention something about \"recycling\" the session and what to do with that\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "p93UImiB2IPr",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 3. Partitioning the Data into Nodes and Edges\n",
        "\n",
        "\n",
        "This Python script is specific to SCOPUS and bibliometric data, though could be easily customized to match the parameters of any data file.\n",
        "\n",
        "To make a network, we must identify objects and relationships between objects. With bibliometric data, we can identify titles and designate a connection between titles if one is referenceing the other. The downloaded Scopus file identifies a title for a source in each row. The column 'References' indicates a semicolon delimited list of references in MLA or APA format. To make this information useful, we must parse an identifying title from each reference in the list. Because the Scopus file does not maintain consistent formatting accross references, we simply keep the entire reference and search for strings inside strings, though this could be customized depending on data file formatting."
      ]
    },
    {
      "metadata": {
        "id": "GoGbS9kK5XOO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "node_list = [] # a list of titles and references\n",
        "edge_list = [] # includes rows of format [a, b] where 'a' references 'b'\n",
        "type_dict = {} # key: node, value: type ('title' or 'reference'), holds all possible node values\n",
        "\n",
        "''' \n",
        "Requires: 'n_type' is either 'title' or 'reference' \n",
        "Modifies: If 'node' occurs in the list, preserves type 'title,' changing either \n",
        "          the 'node_list' value and the 'type_dict' type, or just the 'node' value.\n",
        "          Else, adds 'node' to 'node_list.'\n",
        "Effects:  Compares 'node' to the current 'note_list.' \n",
        "'''\n",
        "def comp_add(node_list, node, n_type):\n",
        "    for i in range(len(node_list)): \n",
        "        # check to see if 'node' compares to any current nodes\n",
        "        if node in node_list[i] or node_list[i] in node: \n",
        "            # if a node exists as a row 'title' and a row 'reference', \n",
        "            # we want to favor the type 'title' in our data structures \n",
        "            if n_type == 'title': \n",
        "                # switch the representation in 'node_list' to 'title'\n",
        "                node_list[i] = node\n",
        "                type_dict[node] = n_type \n",
        "            else:\n",
        "                # switch the representation of 'node' to 'title' \n",
        "                node = node_list[i]\n",
        "            return node \n",
        "        \n",
        "    # the rest of this function executes if 'node' is not already in 'node_list'\n",
        "    if n_type == 'title':\n",
        "        node_list.append(node)\n",
        "        type_dict[node] = n_type\n",
        "    else: \n",
        "        node_list.append(node)\n",
        "        type_dict[node] = n_type\n",
        "\n",
        "    return node"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SBUSRPic5_CF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The following is the main loop to parse data into nodes and edges. "
      ]
    },
    {
      "metadata": {
        "id": "10s8v-_WBIga",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "'''\n",
        "with open(file_name) as csv_file:\n",
        "    reader = csv.DictReader(csv_file)\n",
        "    for row in reader:\n",
        "        # add node with unique identifier\n",
        "        source_node = row['Title']\n",
        "        source_node = comp_add(node_list, source_node, 'title')\n",
        "        # add an edge for each source and its references\n",
        "        refs = row['References'].split(';')\n",
        "        for ref in refs:\n",
        "            # disregard web references, and clean data for any formatting inconsistencies\n",
        "            if 'https://' not in ref and 'http://' not in ref and ref != \" \" and ref != \"\":  \n",
        "                ref = comp_add(node_list, ref, 'reference')\n",
        "                edge = [source_node, ref] # 'source_node' references 'ref'\n",
        "                edge_list.append(edge)\n",
        "                \n",
        "'''\n",
        "\n",
        "# this works\n",
        "for i, row in data.iterrows():\n",
        "  # add node with unique identifier\n",
        "  source_node = row['Title']\n",
        "  source_node = comp_add(node_list, source_node, 'title')\n",
        "  # add an edge for each source and its references\n",
        "\n",
        "  \n",
        "  # check that references exist\n",
        "  refs = row['References']\n",
        "  if type(refs) == str:\n",
        "    # add an edge for each source and its references\n",
        "    refs = refs.split(';')\n",
        "    for ref in refs:\n",
        "        # disregard web references, and clean data for any formatting inconsistencies\n",
        "        if 'https://' not in ref and 'http://' not in ref and ref != \" \" and ref != \"\":  \n",
        "            ref = comp_add(node_list, ref, 'reference')\n",
        "            edge = [source_node, ref] # 'source_node' references 'ref'\n",
        "            edge_list.append(edge)\n",
        "  else: # refs is not a string\n",
        "    pass\n",
        "\n",
        "#   print(row.Title,\"\\n\\n\", row.References, \"\\n\\n\", \"\\n\\n\")\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3vVdUIGH2Rq1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 4. Graph Manipulation\n",
        "Once you have created an <i>edge_list</i> variable, edges can be added to an NetworkX graph. Using NetworkX for this graph manipulation is intuitive and clean, requiring minimal lines of code. We use a directed graph so that we can determine the frequency by which a node is being referenced, as opposed to the frequency by which a node is referencing."
      ]
    },
    {
      "metadata": {
        "id": "NaCPMQ375sxn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "G = nx.DiGraph()\n",
        "for n in node_list: \n",
        "  G.add_node(n)\n",
        "  G.add_edges_from(edge_list)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FTJMCGtj2b5_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "For a large graph, depending on the information being represented, one may want to prune the graph to only contain nodes with a degree (the number of connections to a single node) greater than 1. For this bibliometric data, we are primarily interested in the connections between nodes, therefore a node with only one connection is of much less importance. Furthermore, by removing less significant nodes, we can decrease the graph size significantly, creating a more easily understood graphical layout. Be careful to run this code only as many times as you wish to reduce the graph, or else significant information may be lost as the graph is pruned, depending on the degree of interest in the information."
      ]
    },
    {
      "metadata": {
        "id": "OgPP0NO756FK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# by running this code once, all isolated subgraphs will be removed \n",
        "\n",
        "# first remove nodes of degree 1\n",
        "nodes_to_remove = []\n",
        "for n in G.nodes(): \n",
        "    if G.degree(n) == 1: \n",
        "        nodes_to_remove.append(n)\n",
        "G.remove_nodes_from(nodes_to_remove)\n",
        "\n",
        "# then remove nodes that are isolated \n",
        "nodes_to_remove = []\n",
        "for n in G.nodes(): \n",
        "    if G.degree(n) == 0: \n",
        "        nodes_to_remove.append(n)\n",
        "G.remove_nodes_from(nodes_to_remove)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DxU7y7Z76Ery",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Now that we have pruned our graph, to give the nodes a distinguishable measure, we indicate a label for each node corresponding to its type, and a measure of degree. This part could be customized to distinguish a node by any measure. By adding attributes in this way, they will carry over to HoloViews."
      ]
    },
    {
      "metadata": {
        "id": "eg62a_w76IPr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for n in G.nodes:\n",
        "  G.node[n]['label'] = type_dict[n]\n",
        "# G.node[n]['in-degree'] = G.in_degree(n)\n",
        "  G.node['in_degree'] = G.in_degree(n)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ktyYvqRlVWVQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Next we will run the [Girvan Newman](https://https://networkx.github.io/documentation/latest/reference/algorithms/generated/networkx.algorithms.community.centrality.girvan_newman.html) algorithm on the graph to identify community structure."
      ]
    },
    {
      "metadata": {
        "id": "MR3EQetn6KBJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "communities_generator = community.girvan_newman(G)\n",
        "communities = next(communities_generator)\n",
        "\n",
        "# sort the communities based on size \n",
        "groups = []\n",
        "for c in communities: \n",
        "    size = len(c)\n",
        "    groups.append([size, list(c)])\n",
        "groups.sort(reverse=True)\n",
        "\n",
        "# give each node a community id to which it belongs \n",
        "# groups with a lower 'group_id' will be a member of a larger group\n",
        "group_id = 1\n",
        "for group in groups:\n",
        "    members = group[1]\n",
        "    for n in members: \n",
        "        G.node[n]['community'] = group_id\n",
        "    group_id += 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "79P0gd062o4r",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 5. Creating a Graphical Display"
      ]
    },
    {
      "metadata": {
        "id": "pXTWQmAi6gOw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "See inline comments for any places for further customization. A brief discussion of specific functions and layouts are provided in the GitHub README."
      ]
    },
    {
      "metadata": {
        "id": "eMH2ijvUWPl5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Functionality for the Following Display**\n",
        "\n",
        "Nodes are sized according to their in-degree, a measure of the number of sources that are referencing the node. Colors are assigned according to the NetworkX Girvan Newman community identification algorithm. Edges are bundled to create a clear flow of connection, as opposed to a cluttered, overlapping display. Hover over an edge to identify the end nodes of an edge. End nodes will be highlighted in green when hovering over an edge."
      ]
    },
    {
      "metadata": {
        "id": "F5x-U9hT6StQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The following line is necessary to render graphs in-line in Colaboratory. You may exclude if running locally."
      ]
    },
    {
      "metadata": {
        "id": "0-JEH7jo6RFh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "os.environ['HV_DOC_HTML'] = 'true'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PB_klLTU60vk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "'''The essential functionality'''\n",
        "\n",
        "hv.extension('bokeh')\n",
        "kwargs = dict(width=1000, height=1000, xaxis=None, yaxis=None)\n",
        "hv.opts.defaults(hv.opts.Nodes(**kwargs), hv.opts.Graph(**kwargs))\n",
        "\n",
        "# choose a NetworkX graphical layout \n",
        "pos = nx.spring_layout(G,k=0.15,iterations=20)  \n",
        "\n",
        "# collect graph from NetworkX \n",
        "my_graph = hv.Graph.from_networkx(G, pos)\n",
        "\n",
        "# bundle edges \n",
        "bundled = bundle_graph(my_graph)\n",
        "bundled.opts(padding=0.1) \n",
        "\n",
        "# add community and in-degree features\n",
        "bundled.opts(node_color=hv.dim('community'), node_size=((hv.dim('in-degree') + 1)*5), width=1000, \n",
        "                          cmap='Colorblind')\n",
        "bundled.opts(inspection_policy='edges')\n",
        "\n",
        "\n",
        "'''\n",
        "bib_ops = hv.opts.Graph(node_color=hv.dim('label'), cmap = 'Set1')\n",
        "# collect graph from NetworkX \n",
        "my_graph = hv.Graph.from_networkx(G, pos).opts(bib_ops)\n",
        "# bundle edges \n",
        "bundled = bundle_graph(my_graph)\n",
        "# \n",
        "(datashade(bundled, normalization='linear', width=800, height=800) * bundled.nodes).opts(\n",
        "    opts.Nodes(color=hv.dim('label'), size=10, width=1000, cmap=colors, legend_position='right'))\n",
        "\n",
        "# datashade(bundle_graph(my_graph), normalization='linear', width=900, height=900)\n",
        "#bundled.opts(padding=0.1)\n",
        "\n",
        "# green connection if something is referencing it\n",
        "# orange connection if it is referncing something \n",
        "# blue if title , dark blue if high degree, light blue if small degree \n",
        "# red if resource, dark red if high degree, light red if small degree\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}